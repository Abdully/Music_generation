{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "with open('data/Piano-midi.de.pickle', 'rb') as f:\n",
    "    piano_dataset = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH = '/home/jmcarpenter/git/music-generation/'\n",
    "sys.path.append(os.path.join(PATH, 'midi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "from utils import midiread, midiwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    \n",
    "    # Binarize the pressed notes\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "\n",
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "    \n",
    "    # We hardcode 128 -- because we will always use only\n",
    "    # 128 pitches\n",
    "    \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, :original_piano_roll_length] = piano_roll\n",
    "\n",
    "    return padded_piano_roll\n",
    "\n",
    "\n",
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),\n",
    "                                  midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \"\"\"Recomputes the longest sequence constant of the dataset.\n",
    "\n",
    "        Reads all the midi files from the midi folder and finds the max\n",
    "        length.\n",
    "        \"\"\"\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],\n",
    "                                self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # -1 because we will shift it\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifted by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # pad sequence so that all of them have the same lenght\n",
    "        # Otherwise the batching won't work\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,\n",
    "                                                      max_length=self.longest_sequence_length,\n",
    "                                                      pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),\n",
    "                torch.LongTensor(ground_truth_sequence_padded),\n",
    "                torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    \n",
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    # Here we trim overall data matrix using the size of the longest sequence\n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    # pytorch's api for rnns wants lenghts to be list of ints\n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, lengths_batch_sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset(os.path.join(PATH, 'data/Nottingham/train/'))\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=120,\n",
    "                                              shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(trainset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 1491, 88])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0942e+05)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valset = NotesGenerationDataset(os.path.join(PATH, 'data/Nottingham/valid/'), longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=30, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = next(iter(valset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1229, 88])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25622.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_val[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
