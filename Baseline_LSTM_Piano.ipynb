{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "PATH = '/home/ubuntu/music-generation/'\n",
    "sys.path.append(os.path.join(PATH, 'midi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "from midi_utils import midiread, midiwrite\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = midiread('data/MuseData/train/bach.cant.0001_midip_01.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2661"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_data.piano_roll.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.T\n",
    "    \n",
    "    # Binarize the pressed notes \n",
    "    piano_roll[piano_roll > 0] = 1  # no need as unique values are 0 and 1\n",
    "    \n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "    \"\"\"\n",
    "    padding 0 at the end of sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    # We hardcode 88 -- because we will always use only\n",
    "    # 88 pitches\n",
    "    \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, :original_piano_roll_length] = piano_roll\n",
    "\n",
    "    return padded_piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=None):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),\n",
    "                                  midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \"\"\"Recomputes the longest sequence constant of the dataset.\n",
    "\n",
    "        Reads all the midi files from the midi folder and finds the max\n",
    "        length.\n",
    "        \"\"\"\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],\n",
    "                                self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # -1 because we will shift it\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifted by one time step. from previous step, predict the next one\n",
    "        input_sequence = piano_roll[:, :-1] # skip take the last one\n",
    "        ground_truth_sequence = piano_roll[:, 1:] # skip the first one\n",
    "                \n",
    "        # pad sequence so that all of them have the same lenght\n",
    "        # Otherwise the batching won't work\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,\n",
    "                                                      max_length=self.longest_sequence_length,\n",
    "                                                      pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),\n",
    "                torch.LongTensor(ground_truth_sequence_padded),\n",
    "                torch.LongTensor([sequence_length]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1) \n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    # Here we trim overall data matrix using the size of the longest sequence\n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    # pytorch's api for rnns wants lenghts to be list of ints\n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset(os.path.join(PATH, 'data/MuseData/train/'), longest_sequence_length=None)\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=120,\n",
    "                                              shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(trainset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 2434, 88])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 2434, 88])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 1  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 2  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 3x2434x88]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0  ,.,.) = \n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "      ...         ⋱        ...      \n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       "\n",
       "( 1  ,.,.) = \n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "      ...         ⋱        ...      \n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       "\n",
       "( 2  ,.,.) = \n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "    0    0    0  ...     0    0    0\n",
       "      ...         ⋱        ...      \n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       " -100 -100 -100  ...  -100 -100 -100\n",
       "[torch.LongTensor of size 3x2434x88]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 151\n",
       " 703\n",
       " 119\n",
       " 329\n",
       " 164\n",
       "[torch.LongTensor of size 5x1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2][:5] # sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206176.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = NotesGenerationDataset(os.path.join(PATH, 'data/MuseData/valid/'), longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=30, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = next(iter(valset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2523, 88])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62712.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_input_sequence_batch = X[0].split(split_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitted_input_sequence_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        notes_encoded = self.notes_encoder(input_sequences)\n",
    "        \n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded, input_sequences_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "                \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        neg_logits = (1 - logits)\n",
    "        \n",
    "        # Since the BCE loss doesn't support masking, we use the crossentropy\n",
    "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
    "        \n",
    "        logits_flatten = binary_logits.view(-1, 2)\n",
    "        \n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "\n",
    "    for batch in valset_loader:\n",
    "\n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "        loss = criterion_val(logits, output_sequences_batch_var)\n",
    "\n",
    "        full_val_loss += loss.data[0]\n",
    "        overall_sequence_length += sum(sequences_lengths)\n",
    "\n",
    "    return full_val_loss / (overall_sequence_length * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "epochs_number = 10\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrfinder(start, end, model, trainset_loader, epochs=10):\n",
    "    model.train() # into training mode\n",
    "    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(),start)\n",
    "    loss_list = []\n",
    "    ctr = 0\n",
    "    \n",
    "    for epoch_number in range(epochs):\n",
    "        epoch_loss = []\n",
    "        for batch in trainset_loader:\n",
    "            optimizer.param_groups[0]['lr'] =lrs[ctr]\n",
    "            ctr = ctr+1\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "            loss = criterion(logits, output_sequences_batch_var)\n",
    "            loss_list.append(loss.data[0])\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "    plt.plot(lrs, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "criterion_val = nn.CrossEntropyLoss(size_average=False).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrfinder(1e-3, 0.1, rnn, trainset_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "criterion_val = nn.CrossEntropyLoss(size_average=False).cuda()\n",
    "\n",
    "# learning_rate = 0.005\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "epochs_number = 120\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: Epoch: 0 : 0.6486297845840454\n",
      "Validation Loss: Epoch: 0 : 0.18648934628355707\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.17766371369361877\n",
      "Validation Loss: Epoch: 1 : 0.16665818171657484\n",
      "\n",
      "Training Loss: Epoch: 2 : 0.16188755258917809\n",
      "Validation Loss: Epoch: 2 : 0.16094998097852498\n",
      "\n",
      "Training Loss: Epoch: 3 : 0.16074519604444504\n",
      "Validation Loss: Epoch: 3 : 0.15213753034468555\n",
      "\n",
      "Training Loss: Epoch: 4 : 0.15469951555132866\n",
      "Validation Loss: Epoch: 4 : 0.15134260837702795\n",
      "\n",
      "Training Loss: Epoch: 5 : 0.1528901681303978\n",
      "Validation Loss: Epoch: 5 : 0.14864290494642962\n",
      "\n",
      "Training Loss: Epoch: 6 : 0.14913416653871536\n",
      "Validation Loss: Epoch: 6 : 0.147850978531135\n",
      "\n",
      "Training Loss: Epoch: 7 : 0.15001444891095161\n",
      "Validation Loss: Epoch: 7 : 0.14738433791526515\n",
      "\n",
      "Training Loss: Epoch: 8 : 0.14871039986610413\n",
      "Validation Loss: Epoch: 8 : 0.14633489456415022\n",
      "\n",
      "Training Loss: Epoch: 9 : 0.14909909665584564\n",
      "Validation Loss: Epoch: 9 : 0.14780803625408886\n",
      "\n",
      "Training Loss: Epoch: 10 : 0.1480446308851242\n",
      "Validation Loss: Epoch: 10 : 0.14559980567577238\n",
      "\n",
      "Training Loss: Epoch: 11 : 0.14654987677931786\n",
      "Validation Loss: Epoch: 11 : 0.14556254489147652\n",
      "\n",
      "Training Loss: Epoch: 12 : 0.14722135663032532\n",
      "Validation Loss: Epoch: 12 : 0.14613419707571534\n",
      "\n",
      "Training Loss: Epoch: 13 : 0.14585168659687042\n",
      "Validation Loss: Epoch: 13 : 0.14527413116642193\n",
      "\n",
      "Training Loss: Epoch: 14 : 0.14790109544992447\n",
      "Validation Loss: Epoch: 14 : 0.145405780664404\n",
      "\n",
      "Training Loss: Epoch: 15 : 0.1464892141520977\n",
      "Validation Loss: Epoch: 15 : 0.14550102702586212\n",
      "\n",
      "Training Loss: Epoch: 16 : 0.147186029702425\n",
      "Validation Loss: Epoch: 16 : 0.14528982532966941\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-192:\n",
      "Process Process-189:\n",
      "Process Process-191:\n",
      "Process Process-190:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-13-f2cefe700ec6>\", line 43, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-9-fb603b156949>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-13-f2cefe700ec6>\", line 43, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-13-f2cefe700ec6>\", line 43, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-9-fb603b156949>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"<ipython-input-13-f2cefe700ec6>\", line 43, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"<ipython-input-9-fb603b156949>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 95, in parseMTrkChunk\n",
      "    status = self._running_status = raw_in.readBew()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 29, in __init__\n",
      "    self.piano_roll[int(numpy.ceil(n[1]/dt)) : int(numpy.ceil(n[2]/dt)), n[0]-r[0]] = 1\n",
      "  File \"<ipython-input-9-fb603b156949>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/music-generation/midi/RawInstreamFile.py\", line 82, in readBew\n",
      "    return readBew(self.nextSlice(n_bytes, move_cursor))\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 162, in parseMTrkChunk\n",
      "    dispatch.channel_messages(event_type, channel, channel_data)\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 160, in parseMTrkChunk\n",
      "    channel_data = raw_in.nextSlice(data_size)\n",
      "  File \"/home/ubuntu/music-generation/midi/RawInstreamFile.py\", line 71, in nextSlice\n",
      "    slc = self.data[c:c+length]\n",
      "  File \"/home/ubuntu/music-generation/midi/EventDispatcher.py\", line 92, in channel_messages\n",
      "    stream = self.outstream\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/music-generation/midi/DataTypeConverters.py\", line 61, in readBew\n",
      "    return unpack('>%s' % {1:'B', 2:'H', 4:'L'}[len(value)], value)[0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5f1955c7127a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainset_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpost_processed_batch_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_process_sequence_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "val_list =[]\n",
    "for epoch_number in range(epochs_number):\n",
    "    epoch_loss = []\n",
    "    for batch in trainset_loader:\n",
    "        \n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "        \n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "        \n",
    "        loss = criterion(logits, output_sequences_batch_var)\n",
    "        loss_list.append(loss.data[0])\n",
    "        epoch_loss.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "    print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "    \n",
    "    current_val_loss = validate()\n",
    "    print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "    print('')\n",
    "    \n",
    "    val_list.append(current_val_loss)\n",
    "    \n",
    "    if current_val_loss < best_val_loss:\n",
    "        \n",
    "        torch.save(rnn.state_dict(), 'music_rnn.pth')\n",
    "        best_val_loss = current_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14527413116642193"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_LSTM_Piano.ipynb      data  music_rnn.pth  sample.mid\r\n",
      "Baseline_Sequence_Model.ipynb  midi  README.md\t    sample.midi\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.load_state_dict(torch.load('music_rnn.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(sample_length=4, temperature=1, starting_sequence=None):\n",
    "\n",
    "    if starting_sequence is None:\n",
    "                \n",
    "        current_sequence_input = torch.zeros(1, 1, 88)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
    "\n",
    "    \n",
    "    else:\n",
    "        current_sequence_input = Variable(starting_sequence)\n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "    \n",
    "    hidden = None    \n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
    "\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f341f5219e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(sample_length=200, temperature=0.7).transpose()\n",
    "io.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiwrite('sample.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample.mid' target='_blank'>sample.mid</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/music-generation/sample.mid"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('sample.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = NotesGenerationDataset('data/MuseData/test/', longest_sequence_length=None)\n",
    "\n",
    "testset_loader = torch.utils.data.DataLoader(testset, batch_size=1, \n",
    "                                            shuffle=True, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(testset_loader))\n",
    "post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
    "\n",
    "input_sequences_batch_var = input_sequences_batch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_orig = batch[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3402, 88)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_orig = sample_orig.reshape((3402, 88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiwrite('test0_orig.mid', sample_orig, dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33c8bc0160>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample_orig.transpose()[:,:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='test0_orig.mid' target='_blank'>test0_orig.mid</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/music-generation/test0_orig.mid"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('test0_orig.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 1 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 2 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "... \n",
       "\n",
       "(658,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(659,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(660,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.cuda.FloatTensor of size 661x1x88 (GPU 0)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences_batch_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33c8b554a8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(sample_length=100, temperature=0.7, \n",
    "                               starting_sequence=input_sequences_batch_var).transpose()\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 761)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiwrite('test0.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='test0.mid' target='_blank'>test0.mid</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/music-generation/test0.mid"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('test0.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
