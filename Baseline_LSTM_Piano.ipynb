{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "PATH = '/home/ubuntu/music-generation/'\n",
    "sys.path.append(os.path.join(PATH, 'midi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "from midi_utils import midiread, midiwrite\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as io\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def midi_filename_to_piano_roll(midi_filename):\n",
    "    \n",
    "    midi_data = midiread(midi_filename, dt=0.3)\n",
    "    \n",
    "    piano_roll = midi_data.piano_roll.transpose()\n",
    "    \n",
    "    # Binarize the pressed notes\n",
    "    piano_roll[piano_roll > 0] = 1\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "\n",
    "def pad_piano_roll(piano_roll, max_length=132333, pad_value=0):\n",
    "    \n",
    "    # We hardcode 128 -- because we will always use only\n",
    "    # 128 pitches\n",
    "    \n",
    "    original_piano_roll_length = piano_roll.shape[1]\n",
    "    \n",
    "    padded_piano_roll = np.zeros((88, max_length))\n",
    "    padded_piano_roll[:] = pad_value\n",
    "    \n",
    "    padded_piano_roll[:, :original_piano_roll_length] = piano_roll\n",
    "\n",
    "    return padded_piano_roll\n",
    "\n",
    "\n",
    "class NotesGenerationDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, midi_folder_path, longest_sequence_length=1491):\n",
    "        \n",
    "        self.midi_folder_path = midi_folder_path\n",
    "        \n",
    "        midi_filenames = os.listdir(midi_folder_path)\n",
    "        \n",
    "        self.longest_sequence_length = longest_sequence_length\n",
    "        \n",
    "        midi_full_filenames = map(lambda filename: os.path.join(midi_folder_path, filename),\n",
    "                                  midi_filenames)\n",
    "        \n",
    "        self.midi_full_filenames = list(midi_full_filenames)\n",
    "        \n",
    "        if longest_sequence_length is None:\n",
    "            \n",
    "            self.update_the_max_length()\n",
    "    \n",
    "    \n",
    "    def update_the_max_length(self):\n",
    "        \"\"\"Recomputes the longest sequence constant of the dataset.\n",
    "\n",
    "        Reads all the midi files from the midi folder and finds the max\n",
    "        length.\n",
    "        \"\"\"\n",
    "        \n",
    "        sequences_lengths = map(lambda filename: midi_filename_to_piano_roll(filename).shape[1],\n",
    "                                self.midi_full_filenames)\n",
    "        \n",
    "        max_length = max(sequences_lengths)\n",
    "        \n",
    "        self.longest_sequence_length = max_length\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.midi_full_filenames)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        midi_full_filename = self.midi_full_filenames[index]\n",
    "        \n",
    "        piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
    "        \n",
    "        # -1 because we will shift it\n",
    "        sequence_length = piano_roll.shape[1] - 1\n",
    "        \n",
    "        # Shifted by one time step\n",
    "        input_sequence = piano_roll[:, :-1]\n",
    "        ground_truth_sequence = piano_roll[:, 1:]\n",
    "                \n",
    "        # pad sequence so that all of them have the same lenght\n",
    "        # Otherwise the batching won't work\n",
    "        input_sequence_padded = pad_piano_roll(input_sequence, max_length=self.longest_sequence_length)\n",
    "        \n",
    "        ground_truth_sequence_padded = pad_piano_roll(ground_truth_sequence,\n",
    "                                                      max_length=self.longest_sequence_length,\n",
    "                                                      pad_value=-100)\n",
    "                \n",
    "        input_sequence_padded = input_sequence_padded.transpose()\n",
    "        ground_truth_sequence_padded = ground_truth_sequence_padded.transpose()\n",
    "        \n",
    "        return (torch.FloatTensor(input_sequence_padded),\n",
    "                torch.LongTensor(ground_truth_sequence_padded),\n",
    "                torch.LongTensor([sequence_length]) )\n",
    "\n",
    "    \n",
    "def post_process_sequence_batch(batch_tuple):\n",
    "    \n",
    "    input_sequences, output_sequences, lengths = batch_tuple\n",
    "    \n",
    "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
    "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
    "    splitted_lengths_batch = lengths.split(split_size=1)\n",
    "\n",
    "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
    "                               splitted_output_sequence_batch,\n",
    "                               splitted_lengths_batch)\n",
    "\n",
    "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
    "                                         key=lambda p: int(p[2]),\n",
    "                                         reverse=True)\n",
    "\n",
    "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
    "\n",
    "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
    "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
    "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
    "    \n",
    "    # Here we trim overall data matrix using the size of the longest sequence\n",
    "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0], :]\n",
    "    \n",
    "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
    "    \n",
    "    # pytorch's api for rnns wants lenghts to be list of ints\n",
    "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
    "    lengths_batch_sorted_list = map(lambda x: int(x), lengths_batch_sorted_list)\n",
    "    \n",
    "    return input_sequence_batch_transposed, output_sequence_batch_sorted, list(lengths_batch_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NotesGenerationDataset(os.path.join(PATH, 'data/MuseData/train/'), longest_sequence_length=None)\n",
    "\n",
    "trainset_loader = data.DataLoader(trainset, batch_size=120,\n",
    "                                              shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(trainset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 2434, 88])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228066.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = NotesGenerationDataset(os.path.join(PATH, 'data/MuseData/valid/'), longest_sequence_length=None)\n",
    "\n",
    "valset_loader = data.DataLoader(valset, batch_size=30, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = next(iter(valset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2523, 88])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62712.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.notes_encoder = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        notes_encoded = self.notes_encoder(input_sequences)\n",
    "        \n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(notes_encoded, input_sequences_lengths)\n",
    "        outputs, hidden = self.lstm(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "                \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        neg_logits = (1 - logits)\n",
    "        \n",
    "        # Since the BCE loss doesn't support masking, we use the crossentropy\n",
    "        binary_logits = torch.stack((logits, neg_logits), dim=3).contiguous()\n",
    "        \n",
    "        logits_flatten = binary_logits.view(-1, 2)\n",
    "        \n",
    "        return logits_flatten, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "\n",
    "    full_val_loss = 0.0\n",
    "    overall_sequence_length = 0.0\n",
    "\n",
    "    for batch in valset_loader:\n",
    "\n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "        loss = criterion_val(logits, output_sequences_batch_var)\n",
    "\n",
    "        full_val_loss += loss.data[0]\n",
    "        overall_sequence_length += sum(sequences_lengths)\n",
    "\n",
    "    return full_val_loss / (overall_sequence_length * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "epochs_number = 10\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrfinder(start, end, model, trainset_loader, epochs=20):\n",
    "    model.train() # into training mode\n",
    "    lrs = np.linspace(start, end, epochs*len(trainset_loader))\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters()) # get all parameters which need grad\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(),start)\n",
    "    loss_list = []\n",
    "    ctr = 0\n",
    "    \n",
    "    for epoch_number in range(epochs):\n",
    "        epoch_loss = []\n",
    "        for batch in trainset_loader:\n",
    "            optimizer.param_groups[0]['lr'] =lrs[ctr]\n",
    "            ctr = ctr+1\n",
    "\n",
    "            post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "            input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "            output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "\n",
    "            input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "\n",
    "            loss = criterion(logits, output_sequences_batch_var)\n",
    "            loss_list.append(loss.data[0])\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
    "\n",
    "            optimizer.step()\n",
    "    plt.plot(lrs, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrfinder(1e-4, 1, rnn, trainset_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=88, hidden_size=512, num_classes=88)\n",
    "rnn = rnn.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "criterion_val = nn.CrossEntropyLoss(size_average=False).cuda()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 1.0\n",
    "epochs_number = 120\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: Epoch: 0 : 0.4965091831982136\n",
      "Validation Loss: Epoch: 0 : 0.19657510780643794\n",
      "\n",
      "Training Loss: Epoch: 1 : 0.21182586252689362\n",
      "Validation Loss: Epoch: 1 : 0.21057389689366168\n",
      "\n",
      "Training Loss: Epoch: 2 : 0.21211177483201027\n",
      "Validation Loss: Epoch: 2 : 0.19024841194819825\n",
      "\n",
      "Training Loss: Epoch: 3 : 0.18121786415576935\n",
      "Validation Loss: Epoch: 3 : 0.17232485264097117\n",
      "\n",
      "Training Loss: Epoch: 4 : 0.16939503699541092\n",
      "Validation Loss: Epoch: 4 : 0.16226467365505642\n",
      "\n",
      "Training Loss: Epoch: 5 : 0.1621672585606575\n",
      "Validation Loss: Epoch: 5 : 0.15824039143414942\n",
      "\n",
      "Training Loss: Epoch: 6 : 0.1589542292058468\n",
      "Validation Loss: Epoch: 6 : 0.15427915479926224\n",
      "\n",
      "Training Loss: Epoch: 7 : 0.15483831986784935\n",
      "Validation Loss: Epoch: 7 : 0.1505108132050294\n",
      "\n",
      "Training Loss: Epoch: 8 : 0.15276223421096802\n",
      "Validation Loss: Epoch: 8 : 0.14820039033527552\n",
      "\n",
      "Training Loss: Epoch: 9 : 0.14973077550530434\n",
      "Validation Loss: Epoch: 9 : 0.14859854568610809\n",
      "\n",
      "Training Loss: Epoch: 10 : 0.15011971816420555\n",
      "Validation Loss: Epoch: 10 : 0.14777805022125007\n",
      "\n",
      "Training Loss: Epoch: 11 : 0.1466619148850441\n",
      "Validation Loss: Epoch: 11 : 0.14812689365012144\n",
      "\n",
      "Training Loss: Epoch: 12 : 0.14806955680251122\n",
      "Validation Loss: Epoch: 12 : 0.1472665181288524\n",
      "\n",
      "Training Loss: Epoch: 13 : 0.14652781188488007\n",
      "Validation Loss: Epoch: 13 : 0.1477455884225768\n",
      "\n",
      "Training Loss: Epoch: 14 : 0.14856227487325668\n",
      "Validation Loss: Epoch: 14 : 0.1464965187952639\n",
      "\n",
      "Training Loss: Epoch: 15 : 0.14705006033182144\n",
      "Validation Loss: Epoch: 15 : 0.14614686178747843\n",
      "\n",
      "Training Loss: Epoch: 16 : 0.14937244355678558\n",
      "Validation Loss: Epoch: 16 : 0.1466170832805411\n",
      "\n",
      "Training Loss: Epoch: 17 : 0.14731214568018913\n",
      "Validation Loss: Epoch: 17 : 0.14649648715608393\n",
      "\n",
      "Training Loss: Epoch: 18 : 0.14845984429121017\n",
      "Validation Loss: Epoch: 18 : 0.14665226604869383\n",
      "\n",
      "Training Loss: Epoch: 19 : 0.14693449810147285\n",
      "Validation Loss: Epoch: 19 : 0.14551073686420796\n",
      "\n",
      "Training Loss: Epoch: 20 : 0.14717120304703712\n",
      "Validation Loss: Epoch: 20 : 0.14677260001994533\n",
      "\n",
      "Training Loss: Epoch: 21 : 0.1476389318704605\n",
      "Validation Loss: Epoch: 21 : 0.14552549089182135\n",
      "\n",
      "Training Loss: Epoch: 22 : 0.14956903085112572\n",
      "Validation Loss: Epoch: 22 : 0.14563244487984778\n",
      "\n",
      "Training Loss: Epoch: 23 : 0.14699886739253998\n",
      "Validation Loss: Epoch: 23 : 0.14708571942469195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-204:\n",
      "Process Process-203:\n",
      "Traceback (most recent call last):\n",
      "Process Process-201:\n",
      "Process Process-202:\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 76, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 76, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 76, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 76, in __getitem__\n",
      "    piano_roll = midi_filename_to_piano_roll(midi_full_filename)\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"<ipython-input-11-a13116c1372e>\", line 8, in midi_filename_to_piano_roll\n",
      "    midi_data = midiread(midi_filename, dt=0.3)\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 84, in parseMTrkChunk\n",
      "    while raw_in.getCursor() < track_endposition:\n",
      "  File \"/home/ubuntu/music-generation/midi/midi_utils.py\", line 23, in __init__\n",
      "    midi_in.read()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiInFile.py\", line 48, in read\n",
      "    p.parseMTrkChunks()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 84, in parseMTrkChunk\n",
      "    while raw_in.getCursor() < track_endposition:\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 153, in parseMTrkChunk\n",
      "    NOTE_OFF:2,\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 169, in parseMTrkChunks\n",
      "    self.parseMTrkChunk() # this is where it's at!\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiFileParser.py\", line 88, in parseMTrkChunk\n",
      "    dispatch.update_time(time)\n",
      "  File \"/home/ubuntu/music-generation/midi/EventDispatcher.py\", line 77, in update_time\n",
      "    self.outstream.update_time(new_time, relative)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/ubuntu/music-generation/midi/MidiOutStream.py\", line 41, in update_time\n",
      "    self._relative_time = new_time\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-5f1955c7127a>\", line 5, in <module>\n",
      "    for batch in trainset_loader:\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 275, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 254, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/posixpath.py\", line 408, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "  File \"/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4231) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "val_list =[]\n",
    "for epoch_number in range(epochs_number):\n",
    "    epoch_loss = []\n",
    "    for batch in trainset_loader:\n",
    "        \n",
    "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
    "\n",
    "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
    "\n",
    "        output_sequences_batch_var =  Variable( output_sequences_batch.contiguous().view(-1).cuda() )\n",
    "        \n",
    "        input_sequences_batch_var = Variable( input_sequences_batch.cuda() )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
    "        \n",
    "        loss = criterion(logits, output_sequences_batch_var)\n",
    "        loss_list.append(loss.data[0])\n",
    "        epoch_loss.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    current_trn_epoch = sum(epoch_loss)/len(trainset_loader)\n",
    "    print('Training Loss: Epoch:',epoch_number,':', current_trn_epoch)\n",
    "    \n",
    "    current_val_loss = validate()\n",
    "    print('Validation Loss: Epoch:',epoch_number,':', current_val_loss)\n",
    "    print('')\n",
    "    \n",
    "    val_list.append(current_val_loss)\n",
    "    \n",
    "    if current_val_loss < best_val_loss:\n",
    "        \n",
    "        torch.save(rnn.state_dict(), 'music_rnn.pth')\n",
    "        best_val_loss = current_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14551073686420796"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  DataLoader-Copy1.ipynb  DataLoader.ipynb\tmidi  music_rnn.pth  README.md\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.load_state_dict(torch.load('music_rnn.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_piano_rnn(sample_length=4, temperature=1, starting_sequence=None):\n",
    "\n",
    "    if starting_sequence is None:\n",
    "                \n",
    "        current_sequence_input = torch.zeros(1, 1, 88)\n",
    "        current_sequence_input[0, 0, 40] = 1\n",
    "        current_sequence_input[0, 0, 50] = 0\n",
    "        current_sequence_input[0, 0, 56] = 0\n",
    "        current_sequence_input = Variable(current_sequence_input.cuda())\n",
    "\n",
    "    final_output_sequence = [current_sequence_input.data.squeeze(1)]\n",
    "    \n",
    "    hidden = None\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output, hidden = rnn(current_sequence_input, [1], hidden)\n",
    "\n",
    "        probabilities = nn.functional.softmax(output.div(temperature), dim=1)\n",
    "\n",
    "        current_sequence_input = torch.multinomial(probabilities.data, 1).squeeze().unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        current_sequence_input = Variable(current_sequence_input.float())\n",
    "\n",
    "        final_output_sequence.append(current_sequence_input.data.squeeze(1))\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().numpy()\n",
    "    \n",
    "    return sampled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d57224e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sample_from_piano_rnn(sample_length=200, temperature=0.7).transpose()\n",
    "io.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "midiwrite('sample.mid', sample.transpose(), dt=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample.mid' target='_blank'>sample.mid</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/music-generation/sample.mid"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('sample.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
